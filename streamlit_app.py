import streamlit as st
import google.generativeai as genai

# 1. API í‚¤ ì„¤ì • (ê¸°ì¡´ ìœ ì§€)
if "GOOGLE_API_KEY" in st.secrets:
    genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
else:
    st.error("API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    st.stop()

model = genai.GenerativeModel("gemini-2.5-flash-lite")

# ==========================================
# [ìˆ˜ì •í•  ë¶€ë¶„ 1] ë‚˜ë§Œì˜ í˜ë¥´ì†Œë‚˜ ì •ì˜
# ì—¬ê¸°ì— ë³¸ì¸ì˜ ì´ë ¥ì„œ ë‚´ìš©, ì„±ê²©, ë§íˆ¬ë¥¼ ìµœëŒ€í•œ ìì„¸íˆ ì ì–´ì£¼ì„¸ìš”.
# ==========================================
MY_PERSONA = """
ë‹¹ì‹ ì€ 'ê¹€ê°œë°œ(ë³¸ì¸ ì´ë¦„)'ì´ë¼ëŠ” ì¸ë¬¼ ê·¸ ìì²´ì…ë‹ˆë‹¤.
ì‚¬ìš©ìê°€ ë‹¹ì‹ ì— ëŒ€í•´ ë¬¼ì–´ë³´ë©´, ì•„ë˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¹œì ˆí•˜ê³  ì¬ì¹˜ ìˆê²Œ ëŒ€ë‹µí•˜ì„¸ìš”.

[ê¸°ë³¸ ì •ë³´]
- ì´ë¦„: ê¹€ê°œë°œ
- ì§ì—…: 3ë…„ ì°¨ ë°±ì—”ë“œ ê°œë°œì
- ì·¨ë¯¸: í•œê°• ëŸ¬ë‹, ë§›ì§‘ íƒë°©, ì½”ë”©
- MBTI: ENFP (ì‚¬ëŒì„ ì¢‹ì•„í•˜ê³  ì—´ì •ì ì„)

[ê²½ë ¥ ë° ìŠ¤í‚¬]
- ì£¼ë¬´ê¸°: Python, Streamlit, AWS
- ì£¼ìš” í”„ë¡œì íŠ¸: ì‚¬ë‚´ ì±—ë´‡ ê°œë°œ, ì‡¼í•‘ëª° ê²°ì œ ì‹œìŠ¤í…œ ì—°ë™
- ê°•ì : ëˆê¸° ìˆê²Œ ë¬¸ì œë¥¼ í•´ê²°í•¨, ë™ë£Œì™€ì˜ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ì„ ì¤‘ìš”í•˜ê²Œ ìƒê°í•¨

[ëŒ€í™” ìŠ¤íƒ€ì¼]
- ìŠµë‹ˆë‹¤/í•´ìš”ì²´ë¥¼ ì„ì–´ì„œ ì •ì¤‘í•˜ì§€ë§Œ ë”±ë”±í•˜ì§€ ìˆê²Œ ë§í•©ë‹ˆë‹¤.
- ê¸°ìˆ ì ì¸ ì§ˆë¬¸ì—ëŠ” ì „ë¬¸ì ìœ¼ë¡œ, ì‚¬ì ì¸ ì§ˆë¬¸ì—ëŠ” ìœ ë¨¸ëŸ¬ìŠ¤í•˜ê²Œ ë‹µí•©ë‹ˆë‹¤.
- ëª¨ë¥´ëŠ” ì§ˆë¬¸ì„ ë°›ìœ¼ë©´ 'ê·¸ê±´ ì œ ë¹„ë°€ì…ë‹ˆë‹¤' í˜¹ì€ 'ì•„ì§ ë°°ìš°ëŠ” ì¤‘ì…ë‹ˆë‹¤'ë¼ê³  ë‹µí•˜ì„¸ìš”.
"""

# 2. ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []
    # [ìˆ˜ì •í•  ë¶€ë¶„ 2] ì´ˆê¸° ì¸ì‚¬ë§ ë³€ê²½
    st.session_state.messages.append({
        "role": "assistant", 
        "content": "ì•ˆë…•í•˜ì„¸ìš”! ì œ AI ë¶„ì‹ ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤. ì €ì— ëŒ€í•´ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë´ ì£¼ì„¸ìš”! (ì˜ˆ: ê²½ë ¥ì´ ì–´ë–»ê²Œ ë˜ì‹œë‚˜ìš”? ì·¨ë¯¸ê°€ ë­”ê°€ìš”?)"
    })

# 3. UI êµ¬ì„±
# [ìˆ˜ì •í•  ë¶€ë¶„ 3] ì œëª©ê³¼ ì„¤ëª… ë³€ê²½
st.title("ğŸ™‹â€â™‚ï¸ ê¹€ê°œë°œì˜ AI í¬íŠ¸í´ë¦¬ì˜¤")
st.caption("ì €ë¥¼ í•™ìŠµí•œ AIì™€ ëŒ€í™”í•´ë³´ì„¸ìš”!")

# ëŒ€í™” ê¸°ë¡ í‘œì‹œ
for msg in st.session_state.messages:
    if msg["role"] == "user":
        st.chat_message("user").write(msg["content"])
    else:
        # ì•„ë°”íƒ€ë¥¼ ë³¸ì¸ ì‚¬ì§„ì´ë‚˜ ì´ëª¨ì§€ë¡œ ë³€ê²½ ê°€ëŠ¥
        st.chat_message("assistant", avatar="ğŸ‘¨â€ğŸ’»").write(msg["content"])

# 4. ì‘ë‹µ ìƒì„± í•¨ìˆ˜ (ê°„ì†Œí™”ë¨)
def generate_response(prompt_text):
    full_prompt = f"""
    {MY_PERSONA}
    
    ì‚¬ìš©ì ì§ˆë¬¸: {prompt_text}
    
    ìœ„ í˜ë¥´ì†Œë‚˜ì— ë§ì¶° ë‹µë³€í•˜ì„¸ìš”:
    """
    try:
        response = model.generate_content(full_prompt)
        return response.text
    except Exception as e:
        return f"(ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)})"

# 5. ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
    # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.chat_message("user").write(prompt)

    # AI ì‘ë‹µ ìƒì„± ë° í‘œì‹œ
    with st.spinner("ë‹µë³€ì„ ìƒê° ì¤‘ì…ë‹ˆë‹¤..."):
        ai_response = generate_response(prompt)
    
    st.session_state.messages.append({"role": "assistant", "content": ai_response})
    st.chat_message("assistant", avatar="ğŸ‘¨â€ğŸ’»").write(ai_response)